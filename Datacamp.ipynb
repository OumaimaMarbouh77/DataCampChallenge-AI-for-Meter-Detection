{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Datacamp.ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OumaimaMarbouh77/DataCampChallenge-AI-for-Meter-Detection/blob/main/Datacamp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtTja99D1B_-"
      },
      "source": [
        "#Librairies\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "#import tensorflow as tf\n",
        "import cv2\n",
        "#from tensorflow import keras\n",
        "#from tensorflow.keras.models import Sequential, Model\n",
        "import pathlib\n",
        "from  matplotlib import pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13Xdg1BW3TOS"
      },
      "source": [
        "Connection to drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCRXN9cIuhAq"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUe-2QSe1CAG"
      },
      "source": [
        "#Loading image using PIL in a new window\n",
        "\n",
        "from PIL import Image\n",
        "img_PIL = Image.open(r'/content/drive/MyDrive/DataCampChallenge/train/1ec531.jpg')\n",
        "img_PIL.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6HS55cs1CAH"
      },
      "source": [
        "#Loading image inline using PIL\n",
        "\n",
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "img_PIL = Image.open(r'/content/drive/MyDrive/DataCampChallenge/train/1ec531.jpg')\n",
        "display(img_PIL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAD0_rvYTN5-"
      },
      "source": [
        "\r\n",
        "#Loading image inline using PIL\r\n",
        "\r\n",
        "from IPython.display import display\r\n",
        "from PIL import Image\r\n",
        "img_PIL = Image.open(r'/content/drive/MyDrive/DataCampChallenge/train/0127d0.jpg')\r\n",
        "display(img_PIL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reqwzQ7c1CAH"
      },
      "source": [
        "#Saving image using PIL\n",
        "\n",
        "img_PIL.save(r'/content/drive/MyDrive/DataCampChallenge/train/1ec531.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvaGLioh1CAH"
      },
      "source": [
        "#Loading image using OpenCV\n",
        "\n",
        "image_cv2=cv2.imread(r'/content/drive/MyDrive/DataCampChallenge/train/1ec531.jpg')\n",
        "cv2.imshow(\"Meter Image using OpenCV\", image_cv2)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXW4x0lI1CAI"
      },
      "source": [
        "#Saving the image using OpenCV\n",
        "result=cv2.imwrite(r'/content/drive/MyDrive/DataCampChallenge/train/1ec531.jpg', image_cv2)\n",
        "if result==True:\n",
        "  print(\"File saved successfully\")\n",
        "else:\n",
        "  print(\"Error in saving file\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIOr9U4RS_el"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnBfvghz5yg0"
      },
      "source": [
        "Importing data from index.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_13_m3-s1CAI"
      },
      "source": [
        "train=pd.read_csv(r'/content/drive/MyDrive/DataCampChallenge/index.csv')\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4Sgtti653PG"
      },
      "source": [
        "Processing image data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04JowIy81CAI"
      },
      "source": [
        "IMG_WIDTH=800\n",
        "IMG_HEIGHT=800\n",
        "img_folder_train=r'/content/drive/MyDrive/DataCampChallenge/train'\n",
        "img_folder_test=r'/content/drive/MyDrive/DataCampChallenge/test'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DTH00ES57K8"
      },
      "source": [
        "Image to array and normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DoHCWoE1CAJ"
      },
      "source": [
        "def create_dataset(img_folder):\n",
        "   \n",
        "    img_data_array=[]\n",
        "\n",
        "    for file in os.listdir(img_folder):\n",
        "        image_path= os.path.join(img_folder,  file)\n",
        "        image= cv2.imread( image_path, cv2.COLOR_BGR2RGB)\n",
        "        image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
        "        image=np.array(image)\n",
        "        image = image.astype('float32')\n",
        "        image /= 255 \n",
        "        img_data_array.append(image)\n",
        "    return img_data_array\n",
        "\n",
        "# extract the image array and class name\n",
        "img_data_train=create_dataset(img_folder_train)\n",
        "img_data_test=create_dataset(img_folder_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFVz5k_r1CAJ"
      },
      "source": [
        "img_data_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2pVpdve1CAJ"
      },
      "source": [
        "len(img_data_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJVOd0H5EXXs"
      },
      "source": [
        "Data visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyknSdpF1CAK"
      },
      "source": [
        "plt.figure(figsize=(40,40))\n",
        "img_folder=r'/content/drive/MyDrive/DataCampChallenge/train'\n",
        "for i in range(5):\n",
        "    file = np.random.choice(os.listdir(img_folder))\n",
        "    image_path= os.path.join(img_folder, file)\n",
        "    image= cv2.imread( image_path, cv2.COLOR_BGR2RGB)\n",
        "    image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
        "    #img=mpimg.imread(image_path)\n",
        "    ax=plt.subplot(1,5,i+1)\n",
        "    ax.title.set_text(file)\n",
        "    plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnZ--XCyJSCG"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\r\n",
        "from PIL import Image \r\n",
        "\r\n",
        "frame = cv2.imread('/content/drive/MyDrive/DataCampChallenge/train/cddfb5.jpg')\r\n",
        "# Convert BGR to HSV\r\n",
        "hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\r\n",
        "\r\n",
        "# define range of blue color in HSV\r\n",
        "lower_blue = np.array([110,110,110])\r\n",
        "upper_blue = np.array([255,255,255])\r\n",
        "\r\n",
        "# Threshold the HSV image to get only blue colors\r\n",
        "mask = cv2.inRange(hsv, lower_blue, upper_blue)\r\n",
        "\r\n",
        "# Bitwise-AND mask and original image\r\n",
        "res = cv2.bitwise_and(frame,frame, mask= mask)\r\n",
        "\r\n",
        "plt.imshow(res, interpolation='nearest')\r\n",
        "plt.show()\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5MEW8W8Whmh"
      },
      "source": [
        "### Extraction de la zone digital"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9r2IJccBS2W"
      },
      "source": [
        "img = cv2.imread('/content/drive/MyDrive/DataCampChallenge/train/cddfb5.jpg',0)\r\n",
        "img2 = img.copy()\r\n",
        "template = cv2.imread(r'/content/11eeaa.jpg',0)\r\n",
        "w, h = template.shape[::-1]\r\n",
        "\r\n",
        "# All the 6 methods for comparison in a list\r\n",
        "methods =  ['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR',\r\n",
        "            'cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']\r\n",
        "\r\n",
        "for meth in methods:\r\n",
        "    img = img2.copy()\r\n",
        "    method = eval(meth)\r\n",
        "\r\n",
        "    # Apply template Matching\r\n",
        "    res = cv2.matchTemplate(img,template,method)\r\n",
        "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\r\n",
        "\r\n",
        "    # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\r\n",
        "    if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\r\n",
        "        top_left = min_loc\r\n",
        "    else:\r\n",
        "        top_left = max_loc\r\n",
        "    bottom_right = (top_left[0] + w, top_left[1] + h)\r\n",
        "\r\n",
        "    img_selected=cv2.rectangle(img,top_left, bottom_right, 255, 2)\r\n",
        "\r\n",
        "    plt.subplot(121),plt.imshow(res,cmap = 'gray')\r\n",
        "    plt.title('Matching Result'), plt.xticks([]), plt.yticks([])\r\n",
        "    plt.subplot(122),plt.imshow(img_selected,cmap = 'gray')\r\n",
        "    plt.title('Detected Point'), plt.xticks([]), plt.yticks([])\r\n",
        "    plt.suptitle(meth)\r\n",
        "\r\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frxhAgo3UtZb"
      },
      "source": [
        "img = cv2.imread('/content/drive/MyDrive/DataCampChallenge/train/1ec531.jpg',0)\r\n",
        "img2 = img.copy()\r\n",
        "template = cv2.imread(r'/content/1ec531.jpg',0)\r\n",
        "w, h = template.shape[::-1]\r\n",
        "\r\n",
        "# All the 6 methods for comparison in a list\r\n",
        "methods = ['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR',\r\n",
        "            'cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']\r\n",
        "\r\n",
        "for meth in methods:\r\n",
        "    img = img2.copy()\r\n",
        "    method = eval(meth)\r\n",
        "\r\n",
        "    # Apply template Matching\r\n",
        "    res = cv2.matchTemplate(img,template,method)\r\n",
        "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\r\n",
        "\r\n",
        "    # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\r\n",
        "    if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\r\n",
        "        top_left = min_loc\r\n",
        "    else:\r\n",
        "        top_left = max_loc\r\n",
        "    bottom_right = (top_left[0] + w, top_left[1] + h)\r\n",
        "\r\n",
        "    cv2.rectangle(img,top_left, bottom_right, 255, 2)\r\n",
        "\r\n",
        "    plt.subplot(121),plt.imshow(res,cmap = 'gray')\r\n",
        "    plt.title('Matching Result'), plt.xticks([]), plt.yticks([])\r\n",
        "    plt.subplot(122),plt.imshow(img,cmap = 'gray')\r\n",
        "    plt.title('Detected Point'), plt.xticks([]), plt.yticks([])\r\n",
        "    plt.suptitle(meth)\r\n",
        "\r\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wthd4mCx-z1B"
      },
      "source": [
        "img = cv2.imread('/content/drive/MyDrive/DataCampChallenge/train/1ec531.jpg',0)\r\n",
        "img2 = img.copy()\r\n",
        "template_folder=r'/content/drive/MyDrive/DataCampChallenge/template'\r\n",
        "\r\n",
        "for file in os.listdir(template_folder):\r\n",
        "    file_path= os.path.join(template_folder, file)\r\n",
        "    template = cv2.imread(file_path,0)\r\n",
        "    w, h = template.shape[::-1]\r\n",
        "    # All the 6 methods for comparison in a list\r\n",
        "    methods = ['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR', 'cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']\r\n",
        "\r\n",
        "    for meth in methods:\r\n",
        "      img = img2.copy()\r\n",
        "      method = eval(meth)\r\n",
        "\r\n",
        "      # Apply template Matching\r\n",
        "      res = cv2.matchTemplate(img,template,method)\r\n",
        "      min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\r\n",
        "\r\n",
        "      # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\r\n",
        "      if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\r\n",
        "          top_left = min_loc\r\n",
        "      else:\r\n",
        "          top_left = max_loc\r\n",
        "      bottom_right = (top_left[0] + w, top_left[1] + h)\r\n",
        "\r\n",
        "      cv2.rectangle(img,top_left, bottom_right, 255, 2)\r\n",
        "\r\n",
        "      plt.subplot(121),plt.imshow(res,cmap = 'gray')\r\n",
        "      plt.title('Matching Result'), plt.xticks([]), plt.yticks([])\r\n",
        "      plt.subplot(122),plt.imshow(img,cmap = 'gray')\r\n",
        "      plt.title('Detected Point'), plt.xticks([]), plt.yticks([])\r\n",
        "      plt.suptitle(meth)\r\n",
        "\r\n",
        "      plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOKTzFtp1CAK"
      },
      "source": [
        "Read the image\n",
        "Convert the image from RGB to HSV colorspace\n",
        "Create a mask of the image where the color which falls in a particular range\n",
        "Find the largest contour in the mask image as the display will be the largest contour\n",
        "Create bounding box over the largest contour\n",
        "Extract the bounding box portion from the original image\n",
        "Use adaptive thresholding on the extracted meter display to get a binary image with less amount of noise\n",
        "Further Processing required:\n",
        "\n",
        "Skew Correction of the extracted image\n",
        "Read the digits using OCR to get the meter reading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJtUjT4dEyfM"
      },
      "source": [
        "### PreTraitement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caOOK5r51CAL"
      },
      "source": [
        "\n",
        "class OCRError(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "def get_contours(img):\n",
        "    # img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    edges = cv2.Canny(img, 100, 480, apertureSize=3, L2gradient=True)\n",
        "    # print('edges:', edges)\n",
        "    contours, hierarchy = cv2.findContours(edges.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    # images, contours, hierarchy = cv2.findContours(edges.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    return filter_(contours)\n",
        "\n",
        "\n",
        "def filter_(contours):\n",
        "    contours_dict = dict()\n",
        "    for cont in contours:\n",
        "        x, y, w, h = cv2.boundingRect(cont)\n",
        "        area = cv2.contourArea(cont)\n",
        "        if 10 < area and 10 < w and h > 5:\n",
        "            contours_dict[(x, y, w, h)] = cont\n",
        "    return sorted(contours_dict.values(), key=cv2.boundingRect)\n",
        "\n",
        "\n",
        "def to_contours_image(contours, ref_image):\n",
        "    blank_background = np.zeros_like(ref_image)\n",
        "    img_contours = cv2.drawContours(blank_background, contours, -1, (255, 255, 255), thickness=2)\n",
        "    \n",
        "    return img_contours\n",
        "\n",
        "\n",
        "def is_overlapping_horizontally(box1, box2):\n",
        "    x1, _, w1, _ = box1\n",
        "    x2, _, _, _ = box2\n",
        "    if x1 > x2:\n",
        "        return is_overlapping_horizontally(box2, box1)\n",
        "    return (x2 - x1) < w1\n",
        "\n",
        "\n",
        "def merge(box1, box2):\n",
        "    assert is_overlapping_horizontally(box1, box2)\n",
        "    x1, y1, w1, h1 = box1\n",
        "    x2, y2, w2, h2 = box2\n",
        "    x = min(x1, x2)\n",
        "    w = max(x1 + w1, x2 + w2) - x\n",
        "    y = min(y1, y2)\n",
        "    h = max(y1 + h1, y2 + h2) - y\n",
        "    return x, y, w, h\n",
        "\n",
        "\n",
        "def get_windows(contours):\n",
        "    \"\"\"return List[Tuple[x: Int, y: Int, w: Int, h: Int]]\"\"\"\n",
        "    boxes = []\n",
        "    for cont in contours:\n",
        "        box = cv2.boundingRect(cont)\n",
        "        if not boxes:\n",
        "            boxes.append(box)\n",
        "        else:\n",
        "            if is_overlapping_horizontally(boxes[-1], box):\n",
        "                last_box = boxes.pop()\n",
        "                merged_box = merge(box, last_box)\n",
        "                boxes.append(merged_box)\n",
        "            else:\n",
        "                boxes.append(box)\n",
        "    return boxes\n",
        "\n",
        "\n",
        "def to_digit_images(img):\n",
        "    contours = get_contours(img)\n",
        "    image_contours = to_contours_image(contours, img)\n",
        "    windows = get_windows(contours)\n",
        "    if len(windows) != 7:\n",
        "        raise OCRError\n",
        "    xs = [image_contours[y:y+h, x:x+w] for (x, y, w, h) in windows]\n",
        "    return xs\n",
        "\n",
        "\n",
        "def file2files(fpath):\n",
        "    img = cv2.imread(fpath.as_posix(), cv2.IMREAD_GRAYSCALE)\n",
        "    print('img.shape', img.shape)\n",
        "    rois = to_digit_images(img)\n",
        "    for i, digit_img in enumerate(rois):\n",
        "        outfilepath = fpath.with_name(fpath.stem + ('_%d' % i) + '.png')\n",
        "        cv2.imwrite(outfilepath.as_posix(), digit_img)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnGo953V1CAN"
      },
      "source": [
        "img = cv2.imread(r'/content/drive/MyDrive/DataCampChallenge/train/1ec531.jpg',0)\n",
        "#edges = cv2.Canny(img,80,200)\n",
        "edges = cv2.Canny(img, 100, 440, apertureSize=3, L2gradient=True)\n",
        "\n",
        "contours, hierarchy = cv2.findContours(edges.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "plt.subplot(),plt.imshow(img,cmap = 'gray')\n",
        "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
        "plt.subplot(),plt.imshow(edges,cmap = 'gray')\n",
        "plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTIJxGGm1CAN"
      },
      "source": [
        "contours_dict = dict()\n",
        "for cont in contours:\n",
        "    x, y, w, h = cv2.boundingRect(cont)\n",
        "    area = cv2.contourArea(cont)\n",
        "    if 10 < area and 10 < w and h > 5:\n",
        "        contours_dict[(x, y, w, h)] = cont\n",
        "        \n",
        "contours_filtered =sorted(contours_dict.values(), key=cv2.boundingRect)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8l-hmk61CAO"
      },
      "source": [
        "len(contours_filtered)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZZGt20l1CAO"
      },
      "source": [
        "blank_background = np.zeros_like(edges)\n",
        "img_contours = cv2.drawContours(blank_background, contours_filtered, -1, (255,255,255), thickness=2)\n",
        "# img_contours = cv2.drawContours(blank_background, contours_filtered, -1, (100,100,100), thickness=cv2.FILLED)\n",
        "plt.axis('off')\n",
        "plt.imshow(img_contours, 'gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwIVC6nY1CAM"
      },
      "source": [
        "img = cv2.imread(r'/content/drive/MyDrive/DataCampChallenge/train/1ec531.jpg',0)\n",
        "\n",
        "contours_filtered = get_contours(img)\n",
        "img_contours=to_contours_image(contours_filtered, img)\n",
        "plt.axis('off')\n",
        "plt.imshow(img_contours, 'gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h60GCaqeEnXi"
      },
      "source": [
        "Application on train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0rJmyYA1CAL"
      },
      "source": [
        "img_folder_train=r'/content/drive/MyDrive/DataCampChallenge/train'\n",
        "img_folder_test=r'/content/drive/MyDrive/DataCampChallenge/test'\n",
        "train_files = [file for file in os.listdir(img_folder_train) if file.endswith('.jpg')]\n",
        "test_files = [file for file in os.listdir(img_folder_test) if file.endswith('.jpg')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_o6iMjUo1CAN"
      },
      "source": [
        "contours_filtered_train=[]\n",
        "img_contours_train=[]\n",
        "\n",
        "for file in train_files[0:20]:\n",
        "    image_path= os.path.join(img_folder_train,  file)\n",
        "    image= cv2.imread( image_path, cv2.COLOR_BGR2RGB)\n",
        "    contours_filtered= get_contours(image)\n",
        "    contours_filtered_train.append(get_contours(image)) \n",
        "    img_contours_train.append(to_contours_image(contours_filtered, image))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-z-5iFeIAEg"
      },
      "source": [
        "plt.figure(figsize=(40,40))\r\n",
        "\r\n",
        "for i in range(2):\r\n",
        "    ax=plt.subplot(1,2,i+1)\r\n",
        "    plt.axis('off')\r\n",
        "    plt.imshow(img_contours_train[i], 'gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdGP2cjE1aio"
      },
      "source": [
        "contours_filtered_test=[]\r\n",
        "img_contours_test=[]\r\n",
        "\r\n",
        "for file in test_files[0:20]:\r\n",
        "    image_path= os.path.join(img_folder_test,  file)\r\n",
        "    image= cv2.imread( image_path, cv2.COLOR_BGR2RGB)\r\n",
        "    contours_filtered= get_contours(image)\r\n",
        "    contours_filtered_test.append(get_contours(image)) \r\n",
        "    img_contours_test.append(to_contours_image(contours_filtered, image))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c-fQ4PkIlrS"
      },
      "source": [
        "### Segmentation (Isolate Digits)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8nZi95JIwQQ"
      },
      "source": [
        "def is_overlapping_horizontally(box1, box2):\r\n",
        "    x1, _, w1, _ = box1\r\n",
        "    x2, _, _, _ = box2\r\n",
        "    if x1 > x2:\r\n",
        "        return is_overlapping_horizontally(box2, box1)\r\n",
        "    return (x2 - x1) < w1\r\n",
        "\r\n",
        "def merge(box1, box2):\r\n",
        "    assert is_overlapping_horizontally(box1, box2)\r\n",
        "    x1, y1, w1, h1 = box1\r\n",
        "    x2, y2, w2, h2 = box2\r\n",
        "    x = min(x1, x2)\r\n",
        "    w = max(x1 + w1, x2 + w2) - x\r\n",
        "    y = min(y1, y2)\r\n",
        "    h = max(y1 + h1, y2 + h2) - y\r\n",
        "    return (x, y, w, h)\r\n",
        "\r\n",
        "def windows(contours):\r\n",
        "    \"\"\"return List[Tuple[x: Int, y: Int, w: Int, h: Int]]\"\"\"\r\n",
        "    boxes = []\r\n",
        "    for cont in contours:\r\n",
        "        box = cv2.boundingRect(cont)\r\n",
        "        if not boxes:\r\n",
        "            boxes.append(box)\r\n",
        "        else:\r\n",
        "            if is_overlapping_horizontally(boxes[-1], box):\r\n",
        "                last_box = boxes.pop()\r\n",
        "                merged_box = merge(box, last_box)\r\n",
        "                boxes.append(merged_box)\r\n",
        "            else:\r\n",
        "                boxes.append(box)\r\n",
        "    return boxes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b4iojo9JOPU"
      },
      "source": [
        "\r\n",
        "# assert(len(boxes) == 7)   # Expecting 7 digits\r\n",
        "img = cv2.imread(r'/content/drive/MyDrive/DataCampChallenge/train/1ec531.jpg',0)\r\n",
        "\r\n",
        "contours_filtered = get_contours(img)\r\n",
        "img_contours=to_contours_image(contours_filtered, img)\r\n",
        "plt.axis('off')\r\n",
        "plt.imshow(img_contours, 'gray')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPuhSQ45nLGr"
      },
      "source": [
        "boxes = windows(contours_filtered)\r\n",
        "img_copy = img.copy()\r\n",
        "for box in boxes:\r\n",
        "    x, y, w, h = box\r\n",
        "    img_copy = cv2.rectangle(img_copy, (x, y), (x + w, y + h), (0, 255, 0), 2)\r\n",
        "plt.imshow(img_copy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wAPz3CGFV9B"
      },
      "source": [
        "boxes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACUo4P3MFnF4"
      },
      "source": [
        "boxes[0][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p88FXj1OEym3"
      },
      "source": [
        "x, y, w, h = boxes[0]\r\n",
        "plt.axis('off')\r\n",
        "roi = img_contours[y:y+h, x:x+w]\r\n",
        "plt.imshow(roi)\r\n",
        "cv2.imwrite('testtest.png', roi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yCe5lhGFzs5"
      },
      "source": [
        "contours_filtered = get_contours(roi)\r\n",
        "roi_contours=to_contours_image(contours_filtered, roi)\r\n",
        "plt.axis('off')\r\n",
        "plt.imshow(roi_contours, 'gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMhX58ioIvpZ"
      },
      "source": [
        "image= cv2.imread( roi, cv2.COLOR_BGR2RGB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgJ-OQPIIDBQ"
      },
      "source": [
        "boxes = windows(contours_filtered)\r\n",
        "img = roi.copy()\r\n",
        "for box in boxes:\r\n",
        "    x, y, w, h = box\r\n",
        "    img = cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\r\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5puAJJuwKtyC"
      },
      "source": [
        "### Localize the digit bar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQLap8bdKrju"
      },
      "source": [
        "#'/content/drive/MyDrive/DataCampChallenge/train/1ec531.jpg'\r\n",
        "#'/content/drive/MyDrive/DataCampChallenge/train/0127d0.jpg'\r\n",
        "img = cv2.imread(r'/content/drive/MyDrive/DataCampChallenge/train/1ec531.jpg',0)\r\n",
        "img = cv2.medianBlur(img,5)\r\n",
        "\r\n",
        "ret,th1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\r\n",
        "th2 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11,2)\r\n",
        "th3 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\r\n",
        "\r\n",
        "titles = ['Original Image', 'Global Thresholding (v = 127)',\r\n",
        "            'Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']\r\n",
        "images = [img, th1, th2, th3]\r\n",
        "\r\n",
        "for i in range(4):\r\n",
        "    plt.subplot(2,2,i+1),plt.imshow(images[i],'gray')\r\n",
        "    plt.title(titles[i])\r\n",
        "    plt.xticks([]),plt.yticks([])\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yDIGbxZ0NxW"
      },
      "source": [
        "\r\n",
        "img = cv2.imread('/content/drive/MyDrive/DataCampChallenge/train/1ec531.jpg',0)\r\n",
        "\r\n",
        "# global thresholding\r\n",
        "ret1,th1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\r\n",
        "\r\n",
        "# Otsu's thresholding\r\n",
        "ret2,th2 = cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\r\n",
        "\r\n",
        "# Otsu's thresholding after Gaussian filtering\r\n",
        "blur = cv2.GaussianBlur(img,(5,5),0)\r\n",
        "ret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\r\n",
        "\r\n",
        "# plot all the images and their histograms\r\n",
        "images = [img, 0, th1,\r\n",
        "          img, 0, th2,\r\n",
        "          blur, 0, th3]\r\n",
        "titles = ['Original Noisy Image','Histogram','Global Thresholding (v=127)',\r\n",
        "          'Original Noisy Image','Histogram',\"Otsu's Thresholding\",\r\n",
        "          'Gaussian filtered Image','Histogram',\"Otsu's Thresholding\"]\r\n",
        "\r\n",
        "for i in range(3):\r\n",
        "    plt.subplot(3,3,i*3+1),plt.imshow(images[i*3],'gray')\r\n",
        "    plt.title(titles[i*3]), plt.xticks([]), plt.yticks([])\r\n",
        "    plt.subplot(3,3,i*3+2),plt.hist(images[i*3].ravel(),256)\r\n",
        "    plt.title(titles[i*3+1]), plt.xticks([]), plt.yticks([])\r\n",
        "    plt.subplot(3,3,i*3+3),plt.imshow(images[i*3+2],'gray')\r\n",
        "    plt.title(titles[i*3+2]), plt.xticks([]), plt.yticks([])\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SuenJpPsdgt"
      },
      "source": [
        "NN for object detection/localization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XljdAuJg2IF6"
      },
      "source": [
        "#smoothing\r\n",
        "\r\n",
        "img = cv2.imread(r'/content/drive/MyDrive/DataCampChallenge/train/1ec531.jpg',0)\r\n",
        "\r\n",
        "kernel = np.ones((5,5),np.float32)/25\r\n",
        "dst = cv2.filter2D(img,-1,kernel)\r\n",
        "blur = cv2.GaussianBlur(img,(5,5),0)\r\n",
        "median = cv2.medianBlur(img,5)\r\n",
        "blur2 = cv2.bilateralFilter(img,9,75,75)\r\n",
        "\r\n",
        "plt.subplot(121),plt.imshow(img),plt.title('Original')\r\n",
        "plt.xticks([]), plt.yticks([])\r\n",
        "plt.subplot(122),plt.imshow(dst),plt.title('Averaging')\r\n",
        "plt.xticks([]), plt.yticks([])\r\n",
        "plt.subplot(122),plt.imshow(blur2),plt.title('median')\r\n",
        "plt.xticks([]), plt.yticks([])\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAkP8qpG3dcE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39jQ9Q2LJZik"
      },
      "source": [
        "### Meter- and ID-region Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-xWOLJdJZJx"
      },
      "source": [
        "import os\r\n",
        "import scipy.io\r\n",
        "import scipy.misc\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import PIL\r\n",
        "import struct\r\n",
        "import cv2\r\n",
        "import argparse\r\n",
        "from numpy import expand_dims\r\n",
        "import tensorflow as tf\r\n",
        "from skimage.transform import resize\r\n",
        "from keras import backend as K\r\n",
        "from keras.layers import Input, Lambda, Conv2D, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\r\n",
        "from keras.models import load_model, Model\r\n",
        "from keras.layers.merge import add, concatenate\r\n",
        "from keras.preprocessing.image import load_img\r\n",
        "from keras.preprocessing.image import img_to_array\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from matplotlib.pyplot import imshow\r\n",
        "from matplotlib.patches import Rectangle\r\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Di_nYFZNmsN"
      },
      "source": [
        "#np.set_printoptions(threshold=np.nan)\r\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\r\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\r\n",
        "\r\n",
        "argparser = argparse.ArgumentParser(\r\n",
        "    description='test yolov3 network with coco weights')\r\n",
        "\r\n",
        "argparser.add_argument(\r\n",
        "    '-w',\r\n",
        "    '--weights',\r\n",
        "    help='/content/yolov3.weights')\r\n",
        "\r\n",
        "argparser.add_argument(\r\n",
        "    '-i',\r\n",
        "    '--image',\r\n",
        "    help='/content/1f09ce.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RI5wUO9LCWI"
      },
      "source": [
        "#Create a class WeightReader to load the pre-trained weights for yolov3\r\n",
        "# class to load the pretrained Weights\r\n",
        "class WeightReader:\r\n",
        "    def __init__(self, weight_file):\r\n",
        "        with open(weight_file, 'rb') as w_f:\r\n",
        "            major,    = struct.unpack('i', w_f.read(4))\r\n",
        "            minor,    = struct.unpack('i', w_f.read(4))\r\n",
        "            revision, = struct.unpack('i', w_f.read(4))\r\n",
        "\r\n",
        "            if (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\r\n",
        "                w_f.read(8)\r\n",
        "            else:\r\n",
        "                w_f.read(4)\r\n",
        "\r\n",
        "            transpose = (major > 1000) or (minor > 1000)\r\n",
        "            \r\n",
        "            binary = w_f.read()\r\n",
        "\r\n",
        "        self.offset = 0\r\n",
        "        self.all_weights = np.frombuffer(binary, dtype='float32')\r\n",
        "        \r\n",
        "    def read_bytes(self, size):\r\n",
        "        self.offset = self.offset + size\r\n",
        "        return self.all_weights[self.offset-size:self.offset]\r\n",
        "\r\n",
        "    def load_weights(self, model):\r\n",
        "        for i in range(106):\r\n",
        "            try:\r\n",
        "                conv_layer = model.get_layer('conv_' + str(i))\r\n",
        "                print(\"loading weights of convolution #\" + str(i))\r\n",
        "\r\n",
        "                if i not in [81, 93, 105]:\r\n",
        "                    norm_layer = model.get_layer('bnorm_' + str(i))\r\n",
        "\r\n",
        "                    size = np.prod(norm_layer.get_weights()[0].shape)\r\n",
        "\r\n",
        "                    beta  = self.read_bytes(size) # bias\r\n",
        "                    gamma = self.read_bytes(size) # scale\r\n",
        "                    mean  = self.read_bytes(size) # mean\r\n",
        "                    var   = self.read_bytes(size) # variance            \r\n",
        "\r\n",
        "                    weights = norm_layer.set_weights([gamma, beta, mean, var])  \r\n",
        "\r\n",
        "                if len(conv_layer.get_weights()) > 1:\r\n",
        "                    bias   = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\r\n",
        "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\r\n",
        "                    \r\n",
        "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\r\n",
        "                    kernel = kernel.transpose([2,3,1,0])\r\n",
        "                    conv_layer.set_weights([kernel, bias])\r\n",
        "                else:\r\n",
        "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\r\n",
        "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\r\n",
        "                    kernel = kernel.transpose([2,3,1,0])\r\n",
        "                    conv_layer.set_weights([kernel])\r\n",
        "            except ValueError:\r\n",
        "                print(\"no convolution #\" + str(i))     \r\n",
        "    \r\n",
        "    def reset(self):\r\n",
        "        self.offset = 0\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFDP-sCiONTx"
      },
      "source": [
        "#Create the Yolo v3 model\r\n",
        "class BoundBox:\r\n",
        "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\r\n",
        "        self.xmin = xmin\r\n",
        "        self.ymin = ymin\r\n",
        "        self.xmax = xmax\r\n",
        "        self.ymax = ymax\r\n",
        "        \r\n",
        "        self.objness = objness\r\n",
        "        self.classes = classes\r\n",
        "\r\n",
        "        self.label = -1\r\n",
        "        self.score = -1\r\n",
        "\r\n",
        "    def get_label(self):\r\n",
        "        if self.label == -1:\r\n",
        "            self.label = np.argmax(self.classes)\r\n",
        "        \r\n",
        "        return self.label\r\n",
        "    \r\n",
        "    def get_score(self):\r\n",
        "        if self.score == -1:\r\n",
        "            self.score = self.classes[self.get_label()]\r\n",
        "            \r\n",
        "        return self.score\r\n",
        "\r\n",
        "def _conv_block(inp, convs, skip=True):\r\n",
        "    x = inp\r\n",
        "    count = 0\r\n",
        "    \r\n",
        "    for conv in convs:\r\n",
        "        if count == (len(convs) - 2) and skip:\r\n",
        "            skip_connection = x\r\n",
        "        count += 1\r\n",
        "        \r\n",
        "        if conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) # peculiar padding as darknet prefer left and top\r\n",
        "        x = Conv2D(conv['filter'], \r\n",
        "                   conv['kernel'], \r\n",
        "                   strides=conv['stride'], \r\n",
        "                   padding='valid' if conv['stride'] > 1 else 'same', # peculiar padding as darknet prefer left and top\r\n",
        "                   name='conv_' + str(conv['layer_idx']), \r\n",
        "                   use_bias=False if conv['bnorm'] else True)(x)\r\n",
        "        if conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\r\n",
        "        if conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\r\n",
        "\r\n",
        "    return add([skip_connection, x]) if skip else x\r\n",
        "\r\n",
        "def _interval_overlap(interval_a, interval_b):\r\n",
        "    x1, x2 = interval_a\r\n",
        "    x3, x4 = interval_b\r\n",
        "\r\n",
        "    if x3 < x1:\r\n",
        "        if x4 < x1:\r\n",
        "            return 0\r\n",
        "        else:\r\n",
        "            return min(x2,x4) - x1\r\n",
        "    else:\r\n",
        "        if x2 < x3:\r\n",
        "             return 0\r\n",
        "        else:\r\n",
        "            return min(x2,x4) - x3          \r\n",
        "\r\n",
        "def _sigmoid(x):\r\n",
        "    return 1. / (1. + np.exp(-x))\r\n",
        "\r\n",
        "def bbox_iou(box1, box2):\r\n",
        "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\r\n",
        "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\r\n",
        "    \r\n",
        "    intersect = intersect_w * intersect_h\r\n",
        "\r\n",
        "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\r\n",
        "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\r\n",
        "    \r\n",
        "    union = w1*h1 + w2*h2 - intersect\r\n",
        "    \r\n",
        "    return float(intersect) / union\r\n",
        "\r\n",
        "def make_yolov3_model():\r\n",
        "    input_image = Input(shape=(None, None, 3))\r\n",
        "\r\n",
        "    # Layer  0 => 4\r\n",
        "    x = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\r\n",
        "                                  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\r\n",
        "                                  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\r\n",
        "                                  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\r\n",
        "\r\n",
        "    # Layer  5 => 8\r\n",
        "    x = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\r\n",
        "                        {'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\r\n",
        "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\r\n",
        "\r\n",
        "    # Layer  9 => 11\r\n",
        "    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\r\n",
        "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\r\n",
        "\r\n",
        "    # Layer 12 => 15\r\n",
        "    x = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\r\n",
        "                        {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\r\n",
        "                        {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\r\n",
        "\r\n",
        "    # Layer 16 => 36\r\n",
        "    for i in range(7):\r\n",
        "        x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\r\n",
        "                            {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\r\n",
        "        \r\n",
        "    skip_36 = x\r\n",
        "        \r\n",
        "    # Layer 37 => 40\r\n",
        "    x = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\r\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\r\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\r\n",
        "\r\n",
        "    # Layer 41 => 61\r\n",
        "    for i in range(7):\r\n",
        "        x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\r\n",
        "                            {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\r\n",
        "        \r\n",
        "    skip_61 = x\r\n",
        "        \r\n",
        "    # Layer 62 => 65\r\n",
        "    x = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\r\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\r\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\r\n",
        "\r\n",
        "    # Layer 66 => 74\r\n",
        "    for i in range(3):\r\n",
        "        x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\r\n",
        "                            {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\r\n",
        "        \r\n",
        "    # Layer 75 => 79\r\n",
        "    x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\r\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\r\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\r\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\r\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\r\n",
        "\r\n",
        "    # Layer 80 => 82\r\n",
        "    yolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\r\n",
        "                              {'filter':  255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\r\n",
        "\r\n",
        "    # Layer 83 => 86\r\n",
        "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\r\n",
        "    x = UpSampling2D(2)(x)\r\n",
        "    x = concatenate([x, skip_61])\r\n",
        "\r\n",
        "    # Layer 87 => 91\r\n",
        "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\r\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\r\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\r\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\r\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\r\n",
        "\r\n",
        "    # Layer 92 => 94\r\n",
        "    yolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\r\n",
        "                              {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\r\n",
        "\r\n",
        "    # Layer 95 => 98\r\n",
        "    x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\r\n",
        "    x = UpSampling2D(2)(x)\r\n",
        "    x = concatenate([x, skip_36])\r\n",
        "\r\n",
        "    # Layer 99 => 106\r\n",
        "    yolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\r\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\r\n",
        "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\r\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\r\n",
        "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\r\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\r\n",
        "                               {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\r\n",
        "\r\n",
        "    model = Model(input_image, [yolo_82, yolo_94, yolo_106])    \r\n",
        "    return model\r\n",
        "def preprocess_input(image, net_h, net_w):\r\n",
        "    new_h, new_w, _ = image.shape\r\n",
        "\r\n",
        "    # determine the new size of the image\r\n",
        "    if (float(net_w)/new_w) < (float(net_h)/new_h):\r\n",
        "        new_h = (new_h * net_w)/new_w\r\n",
        "        new_w = net_w\r\n",
        "    else:\r\n",
        "        new_w = (new_w * net_h)/new_h\r\n",
        "        new_h = net_h\r\n",
        "\r\n",
        "    # resize the image to the new size\r\n",
        "    resized = cv2.resize(image[:,:,::-1]/255., (int(new_w), int(new_h)))\r\n",
        "\r\n",
        "    # embed the image into the standard letter box\r\n",
        "    new_image = np.ones((net_h, net_w, 3)) * 0.5\r\n",
        "    new_image[int((net_h-new_h)//2):int((net_h+new_h)//2), int((net_w-new_w)//2):int((net_w+new_w)//2), :] = resized\r\n",
        "    new_image = np.expand_dims(new_image, 0)\r\n",
        "\r\n",
        "    return new_image\r\n",
        "\r\n",
        "def decode_netout(netout, anchors, obj_thresh, nms_thresh, net_h, net_w):\r\n",
        "    grid_h, grid_w = netout.shape[:2]\r\n",
        "    nb_box = 3\r\n",
        "    netout = netout.reshape((grid_h, grid_w, nb_box, -1))\r\n",
        "    nb_class = netout.shape[-1] - 5\r\n",
        "\r\n",
        "    boxes = []\r\n",
        "\r\n",
        "    netout[..., :2]  = _sigmoid(netout[..., :2])\r\n",
        "    netout[..., 4:]  = _sigmoid(netout[..., 4:])\r\n",
        "    netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\r\n",
        "    netout[..., 5:] *= netout[..., 5:] > obj_thresh\r\n",
        "\r\n",
        "    for i in range(grid_h*grid_w):\r\n",
        "        row = i / grid_w\r\n",
        "        col = i % grid_w\r\n",
        "        \r\n",
        "        for b in range(nb_box):\r\n",
        "            # 4th element is objectness score\r\n",
        "            objectness = netout[int(row)][int(col)][b][4]\r\n",
        "            #objectness = netout[..., :4]\r\n",
        "            \r\n",
        "            if(objectness.all() <= obj_thresh): continue\r\n",
        "            \r\n",
        "            # first 4 elements are x, y, w, and h\r\n",
        "            x, y, w, h = netout[int(row)][int(col)][b][:4]\r\n",
        "\r\n",
        "            x = (col + x) / grid_w # center position, unit: image width\r\n",
        "            y = (row + y) / grid_h # center position, unit: image height\r\n",
        "            w = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\r\n",
        "            h = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height  \r\n",
        "            \r\n",
        "            # last elements are class probabilities\r\n",
        "            classes = netout[int(row)][col][b][5:]\r\n",
        "            \r\n",
        "            box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\r\n",
        "            #box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, None, classes)\r\n",
        "\r\n",
        "            boxes.append(box)\r\n",
        "\r\n",
        "    return boxes\r\n",
        "\r\n",
        "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\r\n",
        "    if (float(net_w)/image_w) < (float(net_h)/image_h):\r\n",
        "        new_w = net_w\r\n",
        "        new_h = (image_h*net_w)/image_w\r\n",
        "    else:\r\n",
        "        new_h = net_w\r\n",
        "        new_w = (image_w*net_h)/image_h\r\n",
        "        \r\n",
        "    for i in range(len(boxes)):\r\n",
        "        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\r\n",
        "        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\r\n",
        "        \r\n",
        "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\r\n",
        "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\r\n",
        "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\r\n",
        "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\r\n",
        "        \r\n",
        "def do_nms(boxes, nms_thresh):\r\n",
        "    if len(boxes) > 0:\r\n",
        "        nb_class = len(boxes[0].classes)\r\n",
        "    else:\r\n",
        "        return\r\n",
        "        \r\n",
        "    for c in range(nb_class):\r\n",
        "        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\r\n",
        "\r\n",
        "        for i in range(len(sorted_indices)):\r\n",
        "            index_i = sorted_indices[i]\r\n",
        "\r\n",
        "            if boxes[index_i].classes[c] == 0: continue\r\n",
        "\r\n",
        "            for j in range(i+1, len(sorted_indices)):\r\n",
        "                index_j = sorted_indices[j]\r\n",
        "\r\n",
        "                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\r\n",
        "                    boxes[index_j].classes[c] = 0\r\n",
        "                    \r\n",
        "def draw_boxes(image, boxes, labels, obj_thresh):\r\n",
        "    for box in boxes:\r\n",
        "        label_str = ''\r\n",
        "        label = -1\r\n",
        "        \r\n",
        "        for i in range(len(labels)):\r\n",
        "            if box.classes[i] > obj_thresh:\r\n",
        "                label_str += labels[i]\r\n",
        "                label = i\r\n",
        "                print(labels[i] + ': ' + str(box.classes[i]*100) + '%')\r\n",
        "                \r\n",
        "        if label >= 0:\r\n",
        "            cv2.rectangle(image, (box.xmin,box.ymin), (box.xmax,box.ymax), (0,255,0), 3)\r\n",
        "            cv2.putText(image, \r\n",
        "                        label_str + ' ' + str(box.get_score()), \r\n",
        "                        (box.xmin, box.ymin - 13), \r\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, \r\n",
        "                        1e-3 * image.shape[0], \r\n",
        "                        (0,255,0), 2)\r\n",
        "        \r\n",
        "    return plt.imshow(image)     \r\n",
        "\r\n",
        "def get_boxes(boxes, labels, thresh):\r\n",
        "    v_boxes, v_labels, v_scores = list(), list(), list()\r\n",
        "    # enumerate all boxes\r\n",
        "    for box in boxes:\r\n",
        "        # enumerate all possible labels\r\n",
        "        for i in range(len(labels)):\r\n",
        "            # check if the threshold for this label is high enough\r\n",
        "            if box.classes[i] > thresh:\r\n",
        "                v_boxes.append(box)\r\n",
        "                v_labels.append(labels[i])\r\n",
        "                v_scores.append(box.classes[i]*100)\r\n",
        "                # don't break, many labels may trigger for one box\r\n",
        "    return v_boxes, v_labels, v_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOtHpetZQEf7"
      },
      "source": [
        "# create the yolo v3\r\n",
        "yolov3 = make_yolov3_model()\r\n",
        "# load the weights trained on COCO into the model\r\n",
        "weight_reader = WeightReader(\"yolov3.weights\")\r\n",
        "weight_reader.load_weights(yolov3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIixXKzSSq40"
      },
      "source": [
        "# Setting up the variables\r\n",
        "net_h, net_w = 416, 416\r\n",
        "obj_thresh, nms_thresh = 0.5, 0.45"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAn-mMTLUvYg"
      },
      "source": [
        "#Loading the image into the right input shape of 416x416\r\n",
        "\r\n",
        "from numpy import expand_dims\r\n",
        "def load_image_pixels(filename, shape):\r\n",
        " # load the image to get its shape\r\n",
        " image = load_img(filename)\r\n",
        " width, height = image.size\r\n",
        " \r\n",
        "# load the image with the required size\r\n",
        " image = load_img(filename, target_size=shape)\r\n",
        " # convert to numpy array\r\n",
        " image = img_to_array(image)\r\n",
        "\r\n",
        " #image = image.astype(\"float32\")\r\n",
        " image = tf.image.rgb_to_grayscale(image)\r\n",
        "\r\n",
        " image /= 255.0\r\n",
        " \r\n",
        "# add a dimension so that we have one sample\r\n",
        " image = expand_dims(image, 0)\r\n",
        " return image, width, height"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaNsRMy-Yd2t"
      },
      "source": [
        "from matplotlib.patches import Rectangle\r\n",
        "def draw_boxes(filename, v_boxes, v_labels, v_scores):\r\n",
        " \r\n",
        "# load the image\r\n",
        " data = plt.imread(filename)\r\n",
        " \r\n",
        "# plot the image\r\n",
        " plt.imshow(data)\r\n",
        " \r\n",
        "# get the context for drawing boxes\r\n",
        " ax = plt.gca()\r\n",
        " \r\n",
        "# plot each box\r\n",
        " for i in range(len(v_boxes)):\r\n",
        "   box = v_boxes[i]\r\n",
        "   # get coordinates\r\n",
        "   y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\r\n",
        "   # calculate width and height of the box\r\n",
        "   width, height = x2 - x1, y2 - y1\r\n",
        "  # create the shape\r\n",
        "   rect = Rectangle((x1, y1), width, height, fill=False, color='red')\r\n",
        "  # draw the box\r\n",
        "   ax.add_patch(rect)\r\n",
        "        # draw text and score in top left corner\r\n",
        "   label = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\r\n",
        "   plt.text(x1, y1, label, color='red')\r\n",
        "    # show the plot\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxVCHfuxVfv-"
      },
      "source": [
        "image = load_img('/content/1f09ce.jpg')\r\n",
        "print(image.size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCymmUwfU_XS"
      },
      "source": [
        "image, width, height = load_image_pixels('/content/1f09ce.jpg',(3120, 4160) )\r\n",
        "image.size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_ctwKsCYzf7"
      },
      "source": [
        "weights_path = \"/content/yolov3.weights\"\r\n",
        "image_path   = \"/content/1ec531.jpg\"\r\n",
        "\r\n",
        "# set some parameters\r\n",
        "net_h, net_w = 416, 416\r\n",
        "obj_thresh, nms_thresh = 0.5, 0.45\r\n",
        "anchors = [[116,90,  156,198,  373,326],  [30,61, 62,45,  59,119], [10,13,  16,30,  33,23]]\r\n",
        "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \\\r\n",
        "              \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \\\r\n",
        "              \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \\\r\n",
        "              \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \\\r\n",
        "              \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \\\r\n",
        "              \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \\\r\n",
        "              \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \\\r\n",
        "              \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \\\r\n",
        "              \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \\\r\n",
        "              \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\r\n",
        "\r\n",
        "# make the yolov3 model to predict 80 classes on COCO\r\n",
        "yolov3 = make_yolov3_model()\r\n",
        "\r\n",
        "# load the weights trained on COCO into the model\r\n",
        "weight_reader = WeightReader(weights_path)\r\n",
        "weight_reader.load_weights(yolov3)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKc8OHnJll4Y"
      },
      "source": [
        "3120*4160"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_fal_4YcWTj"
      },
      "source": [
        "\r\n",
        "# preprocess the image\r\n",
        "image = cv2.imread(image_path)\r\n",
        "image_h, image_w, _ = image.shape\r\n",
        "new_image = preprocess_input(image, net_h, net_w)\r\n",
        "#image = load_img('/content/1f09ce.jpg')\r\n",
        "#new_image, width, height = load_image_pixels('/content/1f09ce.jpg', (3120, 4160) )\r\n",
        "# run the prediction\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzgwdFq8mAY9"
      },
      "source": [
        "yolos = yolov3.predict(new_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfN7MEPRoqjI"
      },
      "source": [
        "yolos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BURUs6y9otFk"
      },
      "source": [
        "# summarize the shape of the list of arrays\r\n",
        "print([a.shape for a in yolos])\r\n",
        "\r\n",
        "# define the anchors\r\n",
        "anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\r\n",
        "\r\n",
        "# define the probability threshold for detected objects\r\n",
        "class_threshold = 0.6\r\n",
        "boxes = list()\r\n",
        "for i in range(len(yolos)):\r\n",
        "        # decode the output of the network\r\n",
        "    boxes += decode_netout(yolos[i][0], anchors[i], obj_thresh, nms_thresh, net_h, net_w)\r\n",
        "\r\n",
        "# correct the sizes of the bounding boxes\r\n",
        "correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w)\r\n",
        "# suppress non-maximal boxes\r\n",
        "do_nms(boxes, nms_thresh)\r\n",
        "# get the details of the detected objects\r\n",
        "v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\r\n",
        "# summarize what we found\r\n",
        "for i in range(len(v_boxes)):\r\n",
        "    print(v_labels[i], v_scores[i])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP5CnBH5pJFw"
      },
      "source": [
        "# draw what we found\r\n",
        "draw_boxes(image, v_boxes, v_labels, v_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5RPukjLaPEa"
      },
      "source": [
        "plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8ORfAZNcg4p"
      },
      "source": [
        "new_image.size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_68dbPKad6h"
      },
      "source": [
        "boxes = []\r\n",
        "\r\n",
        "for i in range(len(yolos)):\r\n",
        "  # decode the output of the network\r\n",
        "  boxes += decode_netout(yolos[i][0], anchors[i], obj_thresh, nms_thresh, net_h, net_w)\r\n",
        "\r\n",
        "# correct the sizes of the bounding boxes\r\n",
        "correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w)\r\n",
        "\r\n",
        "# suppress non-maximal boxes\r\n",
        "do_nms(boxes, nms_thresh)     \r\n",
        "\r\n",
        "# draw bounding boxes on the image using labels\r\n",
        "draw_boxes(image, boxes, labels, obj_thresh) \r\n",
        " \r\n",
        "# write the image with bounding boxes to file\r\n",
        "cv2.imwrite(image_path[:-4] + '_detected' + image_path[-4:], (image).astype('uint8')) \r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}